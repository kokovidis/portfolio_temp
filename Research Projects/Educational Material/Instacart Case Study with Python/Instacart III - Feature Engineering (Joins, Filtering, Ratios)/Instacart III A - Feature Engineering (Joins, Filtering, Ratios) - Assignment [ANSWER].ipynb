{
  "cells": [
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "markdown",
      "source": "# Instacart EDA 3 Assignment [ANSWER]\nIn this assignment you will extend the answer of a previous business insight (question 0) and you will create variables that will describe each customer (question 1,2). \n\nFirst load the requested packages and data files for this assignment:"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b8a8af6951ff8ba1a3f10701f67e6baf4e6815e8"
      },
      "cell_type": "code",
      "source": "#load packages\nimport pandas as pd               # for data manipulation\nimport matplotlib.pyplot as plt   # for plotting \nimport seaborn as sns             # an extension of matplotlib for statistical graphics\n\n#load data\norders = pd.read_csv('../input/orders.csv' )\nproducts = pd.read_csv('../input/products.csv')\norder_products_prior = pd.read_csv('../input/order_products__prior.csv')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a9ec107dd81001be8c4f177b50d369e393237c4a"
      },
      "cell_type": "markdown",
      "source": "## Extend the answer of a previous business Insight\n### Question 0: Create the reorder probability and get the names of the products\n1. Follow the steps on  [Chapter 2 of Instacart EDA 2 Notebook](https://www.kaggle.com/kokovidis/instacart-eda-2-notebook)\n to create the reorder probability for each product. Don't forget to use the equivalent filter. Save the results on **reorprob_results** DataFrame\n2. Get the name for the products; use the pandas merge function to combine the results from step 1 with the **products** DataFrame. Use the correct matching key and  perform the appropriate join.\n3. Sort the results so to get the products with the highest ratio first\n4. Visualize the 10 products with the highest ratio and include their names. In order to visualize the labels (ticks) of x-axis properly include the following command in your code before plt.show( ):\n> plt.xticks(size=12, rotation=90)\n\n\n## Create variables that describe each customer\n\n### Question 1: Create a DataFrame that has the orders and the products purchased\n1. Create a DataFrame that contains information for both the orders & order_products_prior DataFrame. Use a inner join and save it as **prd** DataFrame.\n\n### Question 2: Get the average, maximum & minimum order size for each customer.\n\n1. Get for each customer, the size for every of its orders . You will need to use **prd** DataFrame, perform a .groupby( ) on two columns, select the appropiate column and use the correct aggregation function on it. Save the results as **order_size** DataFrame and name the column as **'sizeâ€™**\n2. Get the average order size for each customer by performing a .groupby( ) on **order_size**. Save the outcome as **results** and name the column as **'order_size_avg'**. \n3. Get the smallest & biggest order size for each customer. Perform a .groupby( ) on **order_size**, select the **'size'** column and use one of the following aggregation functions: ![](https://i.imgur.com/N6OeQiX.png)\nSave the outcomes on **results** with two new columns named **'order_size_smallest'** &  **'order_size_biggest'** and display the results.\n4. Find the 10 users with the highest **'order_size_avg'** of **results** DataFrame, save the results as **top10_order_size_avg**. Diplay the results.\n5. Create a histrogram for **'order_size_avg'** of **results**. Use arguments: bins=100."
    },
    {
      "metadata": {
        "_uuid": "c0ab3e515b16671191b7cdc6b0c3fda075d7852d"
      },
      "cell_type": "markdown",
      "source": "## Extend the answer of a previous business Insight\n### Question 0: Create the reorder probability and get the names of the products\n1. Follow the steps on  [Chapter 2 of Instacart EDA 2 Notebook](https://www.kaggle.com/kokovidis/instacart-eda-2-notebook)\n to create the reorder probability for each product. Don't forget to use the equivalent filter. Save the results on **reorprob_results** DataFrame.\n"
    },
    {
      "metadata": {
        "_uuid": "c697a47e852eeecc878f62c4c0478741186c9f67",
        "trusted": true
      },
      "cell_type": "code",
      "source": "reorprob = order_products_prior.groupby('product_id').filter(lambda x: x.shape[0] >40)\nreorprob_results  = reorprob.groupby('product_id', as_index=False)['reordered'].agg('mean')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "53ef45ec5de2cc33fc1fd08c197a99b23995953e"
      },
      "cell_type": "markdown",
      "source": "2. Get the name for the products; use the pandas merge function to combine the results from step 1 with the **products** DataFrame. Use the correct matching key and  perform the appropriate join."
    },
    {
      "metadata": {
        "_uuid": "b0870b2458cdc066a66773575a19fb150c9eb02d",
        "trusted": true
      },
      "cell_type": "code",
      "source": "reorprob_results  = pd.merge(reorprob_results , products, how='left')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b3971f716de264cdc71b378329e641179a79a5d5"
      },
      "cell_type": "markdown",
      "source": "3. Sort the results so to get the products with the highest ratio first."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aaa44765c55a0bd6dd276035cfff170291c5b07f"
      },
      "cell_type": "code",
      "source": "reorprob_results  = reorprob_results.sort_values(by='reordered', ascending=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c26b360967ae276c3326547bed0a74451dce1472"
      },
      "cell_type": "code",
      "source": "reorprob_results.head(20)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0cdb9f6c18ddd8b61c874a998ad363440d34134c"
      },
      "cell_type": "markdown",
      "source": "4. Visualize the 10 products with the highest ratio and include their names. In order to visualize the labels (ticks) of x-axis properly include the following command in your code before plt.show( ):\n> plt.xticks(size=12, rotation=90)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2275755b86750ca7f9976cde9a73fdd6db245ffa"
      },
      "cell_type": "code",
      "source": "reorprob_results  = reorprob_results.iloc[0:10]\n\nplt.figure(figsize=(12,8))\nsns.barplot(reorprob_results.product_name, reorprob_results.reordered, order=reorprob_results.product_name)\nplt.xlabel('10 top products \\n Note that each ID corresponds to a product from products data frame', size=15)\nplt.ylabel('Reorder probability', size=15)\nplt.xticks(size=12, rotation=90)\n#we set the range of y-axis to a bit lower from the lowest probability and a bit higher from the higest probability\nplt.ylim(0.87,0.95)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "76ca5cf77d2cef05905ebadabe1ee9f6bdda64fc"
      },
      "cell_type": "markdown",
      "source": "## Create variables that describe each customer\n### Question 1: Create a DataFrame that has the orders and the products purchased\n1. Create a DataFrame that contains information for both the orders & order_products_prior DataFrame. Use a inner join and save it as **prd** DataFrame."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dc9fbda3f64c592f5f0d40240fdd41d9fc24bdc8"
      },
      "cell_type": "code",
      "source": "# Question 1\nprd = pd.merge(orders, order_products_prior, how='inner')\nprd.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d20faf057dbc652ff625354b630c3bf7bc3421fe"
      },
      "cell_type": "markdown",
      "source": "### Question 2: Get the average, maximum & minimum order size for each customer.\n1. Get for each customer, the size for every of its orders . You will need to use **prd** DataFrame, perform a .groupby( ) on two columns, select the appropiate column and use the correct aggregation function on it. Save the results as **order_size** DataFrame and name the column as **'size'**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1701e6ff81e6775b741a945ce595014b3dc142a6"
      },
      "cell_type": "code",
      "source": "# Question 2 task 1\norder_size = prd.groupby(['user_id', 'order_id'])[['product_id']].count()\norder_size.columns = ['size'] \norder_size.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "62a09610fbfc3eb9ade68cd9253b2f6fe963db95"
      },
      "cell_type": "markdown",
      "source": "2. Get the average order size for each customer by performing a .groupby( ) on **order_size**. Save the outcome as **results** and name the column as **'order_size_avg'**. "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d26228df34a6632cf92215daa5978e48fd37b7d4"
      },
      "cell_type": "code",
      "source": "# Question 2 task 4\nresults = order_size.groupby('user_id')[['size']].mean()\nresults.columns = ['order_size_avg']   \nresults.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "463adeaff54d733c1e6db2d4f63eb5feb0ebeba4"
      },
      "cell_type": "markdown",
      "source": "3. Get the smallest & biggest order size for each customer. Perform a .groupby( ) on **order_size**, select the **'size'** column and use one of the following aggregation functions:\n\n![](https://i.imgur.com/N6OeQiX.png)\n\n\nSave the outcomes on **results** with two new columns named **'order_size_smallest'** &  **'order_size_biggest'** and display the results."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f710ed301491afb400e6923bef246f2f58342aa4"
      },
      "cell_type": "code",
      "source": "# Question 2 task 5\nresults['order_size_smallest'] = order_size.groupby('user_id')['size'].min()\nresults['order_size_biggest'] = order_size.groupby('user_id')['size'].max()\nresults.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0c1c5ffc47752f0cb3c9bcc9ab314f839e6defde"
      },
      "cell_type": "markdown",
      "source": "4. Find the 10 users with the highest **'order_size_avg'** of **results** DataFrame, save the results as **top10_order_size_avg**. Diplay the results.\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b359ad9a62218cc794118acd12d360ba7bc3154b"
      },
      "cell_type": "code",
      "source": "# Question 2 task 7\ntop10_order_size_avg = results.sort_values(by='order_size_avg', ascending=False).iloc[0:10]\ntop10_order_size_avg  ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4aa443d871a2f29cb27f064a035671cb38799cb2"
      },
      "cell_type": "markdown",
      "source": "5. Create a histrogram for **'order_size_avg'** of **results**. Use arguments: bins=100."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4af3b8e77a474c59bb1fa373e056923e71da1200"
      },
      "cell_type": "code",
      "source": "# Question 2 task 8\nplt.hist(results.order_size_avg, bins=100)\nplt.show()",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}